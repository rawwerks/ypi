# RLM Bridge Configuration

# Backend provider (openai, anthropic, etc.)
RLM_BACKEND=openai

# Model to use
RLM_MODEL=gpt-4o-mini

# Maximum recursion depth for RLM
RLM_MAX_RECURSION=10

# Server configuration
RLM_BRIDGE_PORT=8765
RLM_BRIDGE_DEBUG=false

# API keys (set these!)
OPENAI_API_KEY=your-key-here
ANTHROPIC_API_KEY=your-key-here
