# self-experiment.prose
# Test a hypothesis about ypi by running ypi on itself.
#
# Run: rp ypi .prose/self-experiment.prose
#
# Monitor from another terminal:
#   rlm_sessions read --last | tail -30
#   rlm_sessions grep "pattern"

input hypothesis: "What you think will happen and why"
input task: "A concrete coding task that tests the hypothesis"

# --- Design ---

let design = session "Design an A/B experiment"
  prompt: """
    Hypothesis: {hypothesis}
    Task: {task}
    Repo: ypi (recursive coding agent — you ARE running inside it)

    Design a minimal experiment:
    1. What are conditions A and B? (one env var, one prompt change, etc.)
    2. What task do the agents perform? (must be real work on this repo)
    3. What do you measure? (time, accuracy, tool usage, errors hit)
    4. How many trials? (start small — 1 each, scale if promising)

    Write a bash script to experiments/<name>/run.sh that:
    - Takes a condition letter as argument (A, B, C, etc.)
    - Uses rlm_query to spawn children
    - Logs timing and outputs to experiments/<name>/results/<condition>/
    - Uses Pi's default session dir (never override RLM_SESSION_DIR)
    - Is resumable (skip completed trials)

    Keep it simple. We're looking for signal, not statistical significance.
    Return the path to the run script you created.
  """

# --- Run conditions concurrently ---

session "Run all conditions"
  prompt: """
    The experiment script is ready: {design}

    Launch ALL conditions concurrently in separate tmux windows:
    ```
    tmux new-window -t eval -n exp-A; tmux send-keys -t eval:exp-A 'bash <script> A 2>&1 | tee ...' Enter
    tmux new-window -t eval -n exp-B; tmux send-keys -t eval:exp-B 'bash <script> B 2>&1 | tee ...' Enter
    ```

    Then poll for completion (no sleeping):
    - Check `tmux capture-pane -t eval:exp-A -p | grep Results` periodically
    - Once all conditions show results, collect the log files

    Do NOT run conditions sequentially. Do NOT sleep for more than 2 seconds.
  """

# --- Analyze ---

output analysis = session "Analyze results and decide"
  prompt: """
    Hypothesis: {hypothesis}

    Collect results from all conditions (read the log files).

    Analyze:
    1. Did the measured behavior differ between conditions?
    2. Was the hypothesis supported, refuted, or inconclusive?
    3. Recommendation: keep the feature, change it, or kill it?
    4. If inconclusive, what would a better experiment look like?

    Be honest. Negative results are results.
  """
