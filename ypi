#!/bin/bash
# ypi — Y-Combinator Pi — Recursive Coding Agent
#
# Launches Pi as a Recursive Language Model. The LLM gets a system prompt
# that teaches it to use bash + rlm_query for divide-and-conquer reasoning
# over large contexts.
#
# Usage:
#   ypi                              # interactive recursive pi
#   ypi "What is in this repo?"      # one-shot with -p
#   ypi --provider anthropic --model claude-sonnet-4-5-20250929 "question"
#
# Environment overrides:
#   RLM_PROVIDER       — LLM provider for root call (default: cerebras)
#   RLM_MODEL          — LLM model for root call (default: gpt-oss-120b)
#   RLM_MAX_DEPTH      — max recursion depth (default: 3)
#   RLM_TIMEOUT        — wall-clock seconds for entire recursive tree (default: none)
#   RLM_MAX_CALLS      — max total rlm_query invocations (default: none)
#   RLM_CHILD_MODEL    — cheaper model for sub-calls at depth > 0 (default: same as root)
#   RLM_CHILD_PROVIDER — provider for sub-calls at depth > 0 (default: same as root)
#   RLM_JJ             — set to "0" to disable jj workspace isolation (default: 1)
#   RLM_EXTENSIONS     — set to "0" to disable Pi extensions (default: 1)
#   RLM_CHILD_EXTENSIONS — override extensions for depth > 0 (default: same as parent)
#   PI_TRACE_FILE      — path to trace log for all calls with timing (default: none)

set -euo pipefail

# Resolve the directory where ypi lives (and where rlm_query + SYSTEM_PROMPT.md are)
# Follow symlinks — npm install -g creates symlinks in .bin/ pointing to node_modules/ypi/
SCRIPT_DIR="$(cd "$(dirname "$(readlink -f "${BASH_SOURCE[0]}")")" && pwd)"

# Put rlm_query on PATH so Pi's bash tool can find it
export PATH="$SCRIPT_DIR:$PATH"

# Initialize RLM environment — pass through all guardrails
export RLM_DEPTH="${RLM_DEPTH:-0}"
export RLM_MAX_DEPTH="${RLM_MAX_DEPTH:-3}"
export RLM_PROVIDER="${RLM_PROVIDER:-cerebras}"
export RLM_MODEL="${RLM_MODEL:-gpt-oss-120b}"
export RLM_SYSTEM_PROMPT="$SCRIPT_DIR/SYSTEM_PROMPT.md"

# Guardrails — pass through if set, don't override
[ -n "${RLM_TIMEOUT:-}" ]        && export RLM_TIMEOUT
[ -n "${RLM_MAX_CALLS:-}" ]      && export RLM_MAX_CALLS
[ -n "${RLM_CHILD_MODEL:-}" ]    && export RLM_CHILD_MODEL
[ -n "${RLM_CHILD_PROVIDER:-}" ] && export RLM_CHILD_PROVIDER
[ -n "${PI_TRACE_FILE:-}" ]      && export PI_TRACE_FILE
export RLM_JJ="${RLM_JJ:-1}"
export RLM_EXTENSIONS="${RLM_EXTENSIONS:-1}"
[ -n "${RLM_CHILD_EXTENSIONS:-}" ] && export RLM_CHILD_EXTENSIONS

# Session tree tracing — generate a trace ID that links all recursive sessions
export RLM_TRACE_ID="${RLM_TRACE_ID:-$(head -c 4 /dev/urandom | od -An -tx1 | tr -d ' \n')}"

# Compute Pi's session directory for this CWD so children can write there
CWD="$(pwd)"
SAFE_PATH="--$(echo "$CWD" | sed 's|^/||; s|[/:\\]|-|g')--"
export RLM_SESSION_DIR="${HOME}/.pi/agent/sessions/${SAFE_PATH}"
mkdir -p "$RLM_SESSION_DIR"

# Build combined system prompt: SYSTEM_PROMPT.md + rlm_query source
# This way the agent sees the full implementation, not just usage docs.
COMBINED_PROMPT=$(mktemp /tmp/ypi_system_prompt_XXXXXX.md)
trap 'rm -f "$COMBINED_PROMPT"' EXIT

cat "$SCRIPT_DIR/SYSTEM_PROMPT.md" > "$COMBINED_PROMPT"
cat >> "$COMBINED_PROMPT" << 'EOF'

## SECTION 6 – rlm_query Implementation

Below is the full source of `rlm_query`. You are running inside this infrastructure.
Understanding it helps you use recursion effectively and respect guardrails.

```bash
EOF
cat "$SCRIPT_DIR/rlm_query" >> "$COMBINED_PROMPT"
cat >> "$COMBINED_PROMPT" << 'EOF'
```
EOF

# Launch Pi with the combined system prompt, passing all args through
exec pi --system-prompt "$COMBINED_PROMPT" "$@"
